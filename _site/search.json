[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Fahmi Rizaldi",
    "section": "",
    "text": "Hi! I am Fahmi (파흐미). I am a Master Student at the Pusan National University, majoring in Computer Science.\nCurrently I am working as a Research Student under Professor Kwon Joonho at the Data Science Laboratory.\nMy research is about Anomaly Detection."
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "This is the first post in a Quarto blog. Welcome!\n\nSince this post doesn’t specify an explicit image, the first image in the post will be used in the listing page of posts."
  },
  {
    "objectID": "posts/post-with-code/index.html",
    "href": "posts/post-with-code/index.html",
    "title": "Post With Code",
    "section": "",
    "text": "This is a post with executable code."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Fahmi Rizaldi",
    "section": "",
    "text": "Hello! Welcome to my website. Here you can find my recent blogpost regarding my research and my personal academic notes"
  },
  {
    "objectID": "about.html#education",
    "href": "about.html#education",
    "title": "About",
    "section": "",
    "text": "University of California, San Diego | San Diego, CA PhD in Mathematics | Sept 2011 - June 2015\nMacalester College | St. Paul MA B.A in Economics | Sept 2007 - June 2011"
  },
  {
    "objectID": "about.html#experience",
    "href": "about.html#experience",
    "title": "About",
    "section": "",
    "text": "Wengo Analytics | Head Data Scientist | April 2018 - present\nGeoScynce | Chief Analyst | Sept 2012 - April 2018"
  },
  {
    "objectID": "posts/index.html",
    "href": "posts/index.html",
    "title": "Posts",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\n\n\n\nFastAI Lesson 3 “Further Reseach”\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPost With Code\n\n\n\n\n\n\n\n\nFeb 5, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nWelcome To My Blog\n\n\n\n\n\n\n\n\nFeb 2, 2024\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html#textos-recentes-recent-posts",
    "href": "index.html#textos-recentes-recent-posts",
    "title": "Fahmi Rizaldi",
    "section": "Textos recentes / Recent posts",
    "text": "Textos recentes / Recent posts\n\n\n\n\n\n\n\n\n\n\nPost With Code\n\n\n\nFeb 5, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nWelcome To My Blog\n\n\n\nFeb 2, 2024\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html#recent-posts",
    "href": "index.html#recent-posts",
    "title": "Fahmi Rizaldi",
    "section": "Recent posts",
    "text": "Recent posts\n\n\n\n\n\n\n\n\nFastAI Lesson 3 “Further Reseach”\n\n\n\n\n\n\n\n\n\n\n\n\n\nPost With Code\n\n\n\nFeb 5, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nWelcome To My Blog\n\n\n\nFeb 2, 2024\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/fastai-lesson3-recreate/index.html",
    "href": "posts/fastai-lesson3-recreate/index.html",
    "title": "FastAI Lesson 3 “Further Reseach”",
    "section": "",
    "text": "Hi! This is my attempt to do the “Futher Research” part of the FastAI Fastbook Chapter 4 which I recreate using full MNIST datasets and heavily inspired by this blog\nThis is intended to be a learning exercise to slowly learn PyTorch and the FastAI library.\nfrom fastai.vision.all import *\nfrom fastbook import *\n\nmatplotlib.rc('image', cmap='Greys')"
  },
  {
    "objectID": "posts/fastai-lesson3-recreate/index.html#part-1-pixel-similarity",
    "href": "posts/fastai-lesson3-recreate/index.html#part-1-pixel-similarity",
    "title": "FastAI Lesson 3 “Further Reseach”",
    "section": "Part 1: Pixel Similarity",
    "text": "Part 1: Pixel Similarity\nIn this recreation, we are using full MNIST dataset consisting from 0-9 handwriting letter\nWe first “download” the full MNIST dataset and list all the train and validation path\n\nmnist_path = untar_data(URLs.MNIST)\ntrain_path = (mnist_path/'training').ls()\nvalid_path = (mnist_path/'testing').ls()\n\nWe then create a dictionary where the value is the tensor of each image and we create the stacked tensor dictionary where the value is stacked tensor of all images for each digits\n\ntensors_train = {}\nfor digit in train_path:\n    tensors_train[digit.name] = [tensor(Image.open(picture)) for picture in digit.ls()]\n\n\nstacked_tensors_train = {}\nfor digit_tensor in tensors_train.keys():\n    stacked_tensors_train[digit_tensor] = torch.stack(tensors_train[digit_tensor]).float()/255\n\nBy selecting which keys and calculate the mean by selecting the first dimension (0), we are able to see the average images of each class.\n\nmean9 = stacked_tensors_train['9'].mean(0)\nshow_image(mean9)\n\n\n\n\n\n\n\n\nLet us see the distance between one of the 9 and the average 9\n\na_9 = stacked_tensors_train['9'][0]\nshow_image(a_9)\n\n\n\n\n\n\n\n\n\ndist_9_abs = (a_9 - mean9).abs().mean()\ndist_9_sqr = ((a_9 - mean9)**2).mean().sqrt()\ndist_9_abs, dist_9_sqr\n\n(tensor(0.1066), tensor(0.2059))\n\n\n\nmean0 = stacked_tensors_train['0'].mean(0)\n\ndist_0_abs = (a_9 - mean0).abs().mean()\ndist_0_sqr = ((a_9 - mean0)**2).mean().sqrt()\ndist_0_abs, dist_0_sqr\n\n(tensor(0.1844), tensor(0.3134))\n\n\nFrom the calculation we can see that the distance between 9 and the “mean” 9 is less than the distance between 9 and the “mean” 0. By using this distance difference we can classify the digits.\nThis can be calculated using pytorch F class that have similar result\n\nprint(F.l1_loss(a_9, mean9), F.mse_loss(a_9, mean9).sqrt())\nprint(F.l1_loss(a_9, mean0), F.mse_loss(a_9, mean0).sqrt())\n\ntensor(0.1066) tensor(0.2059)\ntensor(0.1844) tensor(0.3134)\n\n\n\ntensors_valid = {}\nfor digit in valid_path:\n    tensors_valid[digit.name] = [tensor(Image.open(picture)) for picture in digit.ls()]\n\nstacked_tensors_valid = {}\nfor digit_tensor in tensors_valid.keys():\n    stacked_tensors_valid[digit_tensor] = torch.stack(tensors_valid[digit_tensor]).float()/255\n\nNow instead calculate the mean for each digits\n\nmodel_mean = {}\nfor digit_tensor in stacked_tensors_valid.keys():\n    model_mean[digit_tensor] = stacked_tensors_train[digit_tensor].mean(0)\n\nfor digit_mean in model_mean.keys():\n    show_image(model_mean[digit_mean])\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ndef mnist_distance(test_image,mean_image): \n    return (test_image-mean_image).abs().mean((-1,-2))\n\n\nprint(stacked_tensors_valid['0'].shape, model_mean['0'].shape)\nvalid_dist = mnist_distance(stacked_tensors_valid['0'], model_mean['0'])\nvalid_dist.shape\n\ntorch.Size([980, 28, 28]) torch.Size([28, 28])\n\n\ntorch.Size([980])\n\n\nmnist_distance will calculate the distance each stack of stack_tensors_valid[‘0’] with model mean of ‘0’ with resulted a torch size equal to the number of stack of stack_tensor_valid\n\nvalid_dist = torch.stack([mnist_distance(stacked_tensors_valid['0'], model_mean[o]) for o in model_mean.keys()])\nvalid_dist, valid_dist.shape\n\n(tensor([[0.1298, 0.1337, 0.1540,  ..., 0.1307, 0.1248, 0.1627],\n         [0.1822, 0.1556, 0.1623,  ..., 0.2321, 0.2238, 0.2341],\n         [0.1781, 0.1580, 0.1730,  ..., 0.2318, 0.2206, 0.2314],\n         ...,\n         [0.1946, 0.1567, 0.1768,  ..., 0.2283, 0.2128, 0.2416],\n         [0.1775, 0.1466, 0.1838,  ..., 0.2144, 0.1954, 0.2101],\n         [0.1976, 0.1463, 0.1867,  ..., 0.2235, 0.2095, 0.2265]]),\n torch.Size([10, 980]))\n\n\nFrom there we improve so that it calculate the distance to each digit of model mean and stack it.\n\nmin_values, min_indices = torch.min(valid_dist, dim=0)\nis_correct = min_indices == int(list(model_mean.keys())[0])\naccuracy_each = is_correct.float().mean()\naccuracy_each\n\ntensor(0.8153)\n\n\nWe can then calculate the accuracy by:\n\nOn valid_dist stack_tensor we find the index of minimum value\nWe then check if the minimum indices is the same as the correct digit\ncalculate the accuracy by calculating the mean of the is_correct bollean list\n\n\ndef calc_acc(an_image_tensor, keys):\n    valid_dist = torch.stack([mnist_distance(an_image_tensor, model_mean[o]) for o in model_mean.keys()])\n    min_values, min_indices = torch.min(valid_dist, dim=0)\n    is_correct = min_indices == int(list(model_mean.keys())[int(keys)])\n    accuracy = is_correct.float().mean()\n    return accuracy\n\nacc = torch.stack([calc_acc(stacked_tensors_valid[keys], keys) for keys in stacked_tensors_valid.keys()])\nacc.mean()\n\ntensor(0.6610)\n\n\nCombine everything in calc_acc, and instead of only calculating the accuracy for one digit, we calculate for every digit and find the mean. The mean will be our model’s accuracy."
  },
  {
    "objectID": "posts/fastai-lesson3-recreate/index.html#part-2-learner",
    "href": "posts/fastai-lesson3-recreate/index.html#part-2-learner",
    "title": "FastAI Lesson 3 “Further Reseach”",
    "section": "Part 2: Learner",
    "text": "Part 2: Learner\nNow we want to improve the model accuracy by using regression model\nFor the data preparation, instead of using dictionary, we create a list of pair where the first dimension is x_data and second dimension is y_data\n\ntrain_path = (mnist_path/'training').ls()\nvalid_path = (mnist_path/'testing').ls()\n\n\ntensors_train = [(tensor(Image.open(each_image)), int(digit_file.name)) for digit_file in train_path for each_image in digit_file.ls()]\ntensors_valid = [(tensor(Image.open(each_image)), int(digit_file.name)) for digit_file in valid_path for each_image in digit_file.ls()]\nnp.random.shuffle(tensors_train)\nnp.random.shuffle(tensors_valid)\n\nSo what tensors_train contain is:\n\ntensors is list with 60.000 element\ntensors[] is tuple with 2 elements\ntensors[][0] is tensor of images value 28x28\ntensors[][1] is the label\n\n\nprint(len(tensors_train))\nprint(len(tensors_train[0]))\nprint(len(tensors_train[0][0]))\nprint(tensors_train[0][1])\nprint(len(tensors_valid))\n\n60000\n2\n28\n5\n10000\n\n\n\ntrain_x = torch.cat([tensors_train[each_stack][0].view(-1, 784).float()/255 for each_stack in range(len(tensors_train))])\ntrain_y = tensor([tensors_train[each_stack][1] for each_stack in range(len(tensors_train))])\n\nvalid_x = torch.cat([tensors_valid[each_stack][0].view(-1, 784).float()/255 for each_stack in range(len(tensors_valid))])\nvalid_y = tensor([tensors_valid[each_stack][1] for each_stack in range(len(tensors_valid))])\n\ntrain_ and valid_ structure:\n\ntrain_ is tensor with 48.000 stack of 784 tensor of flattened image (28x28)\nvalid_ is tensor with len 48.000 which are the class label of each train_ stack\n\n\nprint(train_x.shape)\nprint(train_y.shape)\nprint(valid_x.shape)\nprint(valid_y.shape)\n\ntorch.Size([60000, 784])\ntorch.Size([60000])\ntorch.Size([10000, 784])\ntorch.Size([10000])\n\n\n\ndset_train = list(zip(train_x, train_y))\ndset_valid = list(zip(valid_x, valid_y))\n\ndset and valid_dset is pair of data and label:\n\ndset is length of 48.000 data\ndset[] is each pair\ndset[][0] is the x and dset[][1] is the y\n\n\nprint(len(dset_train))\nprint(len(dset_train[0]))\nprint(len(dset_train[0][0]))\nprint(dset_train[0][0].shape)\nprint(dset_train[0][1].shape)\n\n60000\n2\n784\ntorch.Size([784])\ntorch.Size([])\n\n\n\nprint(len(dset_valid))\nprint(len(dset_valid[0]))\nprint(len(dset_valid[0][0]))\nprint(dset_valid[0][1])\n\n10000\n2\n784\ntensor(7)\n\n\nCreate function to initialize parameter that give output a tensor with desired size\n\ndef init_params(size, std=1.0): return (torch.randn(size) * std).requires_grad_()\n\n\nweights = init_params(((28*28), 10))\nbias = init_params((1, 10))\n\nBecause this one is a linear type classifier, we need to have 10 stack of weights for each digits. It is different from neural networks based where we used 1 set of weights\n\nprint(train_x[0].shape, \"-&gt; its equal to [1, 784]\")\nprint(weights.shape)\npred = train_x[0]@weights + bias\nprint(pred)\nprint(pred.shape)\n\ntorch.Size([784]) -&gt; its equal to [1, 784]\ntorch.Size([784, 10])\ntensor([[-12.8129,  15.3278,   4.1641,   1.6066,   4.2265,  11.4496,  19.4137,   2.0250,  25.2653,  -6.6110]], grad_fn=&lt;AddBackward0&gt;)\ntorch.Size([1, 10])\n\n\nThis doenst quiet represent anything yet. We need to use softmax to convert the output to probabilities.\n\ndef linear1(x_matrix): return x_matrix@weights + bias\npred = linear1(train_x)\npred_prob = F.softmax(pred, dim=1)\nprint(pred_prob)\nprint(pred_prob.shape)\n\ntensor([[2.8946e-17, 4.8186e-05, 6.8328e-10,  ..., 8.0465e-11, 9.9708e-01, 1.4290e-14],\n        [1.5549e-08, 1.6647e-08, 4.7936e-06,  ..., 2.1437e-15, 1.4793e-04, 1.3994e-09],\n        [8.0650e-07, 3.7267e-06, 1.1988e-05,  ..., 1.3478e-02, 5.2920e-04, 3.1845e-03],\n        ...,\n        [6.0731e-07, 4.7170e-01, 2.7054e-08,  ..., 2.0115e-10, 4.8844e-01, 3.8189e-02],\n        [9.2131e-01, 1.5331e-07, 3.5232e-07,  ..., 2.0329e-11, 1.8150e-04, 1.7378e-14],\n        [6.7177e-07, 3.1652e-04, 1.0417e-06,  ..., 4.6246e-02, 3.6580e-07, 4.9520e-09]], grad_fn=&lt;SoftmaxBackward0&gt;)\ntorch.Size([60000, 10])\n\n\npred_prob store probability of each image for all digits.\nThen we try to calculate the accuracy\n\nacc = tensor([torch.argmax(pred_prob[i]) == train_y[i] for i in range(len(pred_prob))])\nacc.float().mean()\n\ntensor(0.0683)\n\n\nWhat it acc did:\n\nFor every stack of pred_prob tensor, it find the index of the highest probability and return the index.\nAfter finding the index it do bollean check to see if the index is equal to the actual label.\nWe then calculate the mean to see the accuracy\n\nLets try to update the weight to see if there is any significant change\n\nweights[0]\n\ntensor([ 1.1152,  0.6064,  0.9859,  1.4940,  1.9783,  0.3804,  0.0418,  0.2844, -0.3880, -0.7500], grad_fn=&lt;SelectBackward0&gt;)\n\n\n\nwith torch.no_grad(): weights[0] *= 1.0001\npred = linear1(train_x)\npred_prob = F.softmax(pred, dim=1)\nacc = tensor([torch.argmax(pred_prob[i]) == train_y[i] for i in range(len(pred_prob))])\nacc.float().mean()\n\ntensor(0.0683)\n\n\nAs you can see the accuracy didnt change visibly. This means that we need to find better metrics to evaluate our model.\nBecause the change in weight SHOULD BE change how our model works (for better or worse)\nWe will use what we call a binary cross entory loss (I will make other post on that later, for now please look for your own reference)\n\ndef mnist_loss(predictions, targets):\n    loss = F.cross_entropy(predictions, targets.squeeze())\n    return loss\n\n\nloss = mnist_loss(pred, train_y)\nprint(loss)\n\nloss.backward() \nweights.grad.shape,weights.grad.mean(),bias.grad.shape\n\ntensor(14.6460, grad_fn=&lt;NllLossBackward0&gt;)\n\n\n(torch.Size([784, 10]), tensor(-1.5205e-10), torch.Size([1, 10]))\n\n\nHere we can have gradient for each weight of each pixel (therefore we have torch.Size([784, 10])\n\ndef calc_grad(x_data, y_data, model):\n    preds = model(x_data)\n    loss = mnist_loss(preds, y_data)\n    loss.backward()\n\ncalc_grad(train_x, train_y, linear1)\nweights.grad.mean()\n\ntensor(-3.0411e-10)\n\n\n\nprint(train_x.shape)\nprint(train_y.shape)\n\ntorch.Size([60000, 784])\ntorch.Size([60000])\n\n\nFor every epoch, we need to set the gradient into zero to make sure it didnt add onto existing gradient (as it do in in default)\n\ntrain_batches = DataLoader(dset_train, batch_size=256)\nvalid_batches = DataLoader(dset_valid, batch_size=256)\nxb,yb = first(train_batches)\n\n\nprint(len(train_batches))\nprint(xb.shape)\nprint(yb.shape)\n\n235\ntorch.Size([256, 784])\ntorch.Size([256])\n\n\nSo what dataloader do is to create a batch of x and y data from the dset_ dataset (thats why it has 60.000 / 256 = 235 len)\n\ndef train_epoch(model, learn_rate, params):\n    for x_data, y_data in train_batches:\n        calc_grad(x_data, y_data, model)\n        for p in params:\n            p.data -= p.grad*lr\n            p.grad.zero_()\n\nWhat it did is for each epoch it learn update the params (in this case is weights AND bias thats why its done in loop) based on the gradients that calculated in each loop train dataset\n\ndef batch_accuracy(x_data, y_data):\n    preds = F.softmax(x_data, dim=1)\n    correct = torch.argmax(preds, dim=1) == y_data\n    return correct.float().mean()\n\nWe still need to use accuracy to measure the final performance after adjustment\n\nbatch_accuracy(linear1(train_x), train_y)\n\ntensor(0.0683)\n\n\n\ndef validate_epoch(model):\n    accs = [batch_accuracy(model(xb), yb) for xb,yb in valid_batches]\n    return round(torch.stack(accs).mean().item(), 4)\n\nvalidate_epoch(linear1)\n\n0.0753\n\n\nThe accuracy is used to validate each epoch\n\nlr = 1.\nparams = weights,bias\ntrain_epoch(linear1, lr, params)\nvalidate_epoch(linear1)\n\n0.8472\n\n\nFrom just one epoch we can get the 84% accuracy\nNow lets try to train 20 epoch\n\nfor i in range(20):\n    train_epoch(linear1, lr, params)\n    print(validate_epoch(linear1), end=' ')\n\n0.8754 0.8839 0.8918 0.8982 0.9018 0.9041 0.9056 0.9065 0.9085 0.9093 0.9112 0.9131 0.9138 0.9144 0.9141 0.9137 0.9142 0.9142 0.9144 0.9145 \n\n\nHere we go, just using very2 basic linear regression model we can have 91% accuracy.\nThe next iteration of model using neural network will be done on another post.\nPlease kindly submit your comments and suggestions to my email address: fahmi.rizaldi@gmail.com"
  }
]